{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TX7PuOcOZytb"
      },
      "outputs": [],
      "source": [
        "import jax \n",
        "jax.config.update(\"jax_enable_x64\", True)\n",
        "import jax.numpy as jnp\n",
        "import numpy as np \n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(jax.devices())\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcGA0dsuaI6I"
      },
      "source": [
        "\n",
        "We consider a classical Coulomb gas with the Hamiltonian \n",
        "\n",
        "$$H= \\sum_{i<j} \\frac{1}{|\\boldsymbol{x}_i - \\boldsymbol{x}_j|} + \\sum_i  \\boldsymbol{x}_i^2 , $$\n",
        "where the two terms are Coulomb interaction and harmonic trapping potential respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3fm-jEwaAC2"
      },
      "outputs": [],
      "source": [
        "def energy_fn(x, n, dim):\n",
        "    i, j = jnp.triu_indices(n, k=1)\n",
        "    rij = jnp.linalg.norm((jnp.reshape(x, (n, 1, dim)) - jnp.reshape(x, (1, n, dim)))[i,j], axis=-1)\n",
        "    return jnp.sum(x**2) + jnp.sum(1/rij)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0awpHGTI7Kuc"
      },
      "source": [
        "We can obtain the gradient function via `jax.grad`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjt0TjqbaklF"
      },
      "outputs": [],
      "source": [
        "grad_fn = jax.grad(energy_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRqHwXIj4woK"
      },
      "source": [
        "Let's have a look at particles and force"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "fFtVZvABdrFH",
        "outputId": "0f1d3b53-89bb-4f2f-f56c-18f50394b000"
      },
      "outputs": [],
      "source": [
        "n, dim = 20, 2\n",
        "key = jax.random.PRNGKey(42)\n",
        "x = jax.random.normal(key, (n, dim)) # random particle position\n",
        "f = grad_fn(x, n, dim)\n",
        "\n",
        "fig = plt.figure(figsize=(6, 6), dpi=300)\n",
        "plt.scatter(x[:, 0], x[:, 1])\n",
        "plt.quiver(x[:, 0], x[:, 1], f[:, 0], f[:, 1], color='red', scale=1)\n",
        "\n",
        "plt.xlim([-3, 3])\n",
        "plt.ylim([-3, 3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmLmup2UtfTR"
      },
      "source": [
        "## Ground state \n",
        "\n",
        "We want to find the minimal energy configuration\n",
        "\n",
        "$$x^\\ast  = \\mathrm{argmin}_{x} H(x) .$$\n",
        "\n",
        "For that, we carry out a gradient descent\n",
        "\n",
        "$$x \\leftarrow x - \\eta \\frac{\\partial H }{\\partial x}$$ \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YLXM0Y0a7qO"
      },
      "outputs": [],
      "source": [
        "def optimize(x, steps=500, eta=1e-2):\n",
        "    for _ in range(steps):\n",
        "        x = x - eta * grad_fn(x, n, dim)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfJQaBVu5O1_"
      },
      "source": [
        "Run the optimization, and have a look at the result!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XexxS9tejPpa"
      },
      "outputs": [],
      "source": [
        "x = optimize(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "-b6UkXPIbRvR",
        "outputId": "b5c38bbe-e122-4531-ada3-429dd4a0c5de"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(6, 6))\n",
        "\n",
        "f = grad_fn(x, n, dim)\n",
        "plt.scatter(x[:, 0], x[:, 1])\n",
        "plt.quiver(x[:, 0], x[:, 1], f[:, 0], f[:, 1], color='red', scale=1)\n",
        "\n",
        "plt.xlim([-3, 3])\n",
        "plt.ylim([-3, 3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVpQkfCt5v0R"
      },
      "source": [
        "We can actually run a batch of optimizations in parallel with `vmap`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RDpZMRxjqMA"
      },
      "outputs": [],
      "source": [
        "batchsize = 64\n",
        "x = jax.random.normal(key, (batchsize, n, dim))\n",
        "x = jax.vmap(optimize)(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "2yxuTZbFjwQb",
        "outputId": "1e8520aa-4d40-4b38-d480-73d455b8530e"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(6, 6))\n",
        "\n",
        "for b in range(batchsize):\n",
        "    plt.scatter(x[b, :, 0], x[b, :, 1], alpha=0.5, color='b')\n",
        "plt.xlim([-3, 3])\n",
        "plt.ylim([-3, 3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huP7OqtatjhH"
      },
      "source": [
        "## Finite temperature\n",
        "\n",
        "We want to sample configuation from the equlibrium Boltzman distribution \n",
        "\n",
        "$$ x\\sim \\frac{e^{-\\beta H(x)}}{Z}. $$ \n",
        "\n",
        "\n",
        "For that, we will use the Metropolis Monte Carlo algorithms. We randomly move the particles, and accept the move with probability \n",
        "\n",
        "$$ A(x \\rightarrow x^\\prime ) = \\min \\left[ 1, \\frac{e^{-\\beta H(x^\\prime)}}{e ^{-\\beta H(x)}} \\right] $$ \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9A9hezNkvLqM"
      },
      "outputs": [],
      "source": [
        "@partial(jax.jit, static_argnums=0)\n",
        "def mcmc(logp_fn, x_init, key, mc_steps, mc_width):\n",
        "    \"\"\"\n",
        "        Markov Chain Monte Carlo sampling algorithm.\n",
        "\n",
        "    INPUT:\n",
        "        logp_fn: callable that evaluate log-probability of a batch of configuration x.\n",
        "            The signature is logp_fn(x), where x has shape (batch, n, dim).\n",
        "        x_init: initial value of x, with shape (batch, n, dim).\n",
        "        key: initial PRNG key.\n",
        "        mc_steps: total number of Monte Carlo steps.\n",
        "        mc_width: size of the Monte Carlo proposal.\n",
        "\n",
        "    OUTPUT:\n",
        "        x: resulting batch samples, with the same shape as `x_init`.\n",
        "    \"\"\"\n",
        "    def step(i, state):\n",
        "        x, logp, key, num_accepts = state\n",
        "        key, key_proposal, key_accept = jax.random.split(key, 3)\n",
        "        \n",
        "        x_proposal = x + mc_width * jax.random.normal(key_proposal, x.shape)\n",
        "        logp_proposal = logp_fn(x_proposal)\n",
        "\n",
        "        ratio = jnp.exp((logp_proposal - logp))\n",
        "        accept = jax.random.uniform(key_accept, ratio.shape) < ratio\n",
        "\n",
        "        x_new = jnp.where(accept[:, None, None], x_proposal, x)\n",
        "        logp_new = jnp.where(accept, logp_proposal, logp)\n",
        "        num_accepts += accept.sum()\n",
        "        return x_new, logp_new, key, num_accepts\n",
        "    \n",
        "    logp_init = logp_fn(x_init)\n",
        "\n",
        "    x, logp, key, num_accepts = jax.lax.fori_loop(0, mc_steps, step, (x_init, logp_init, key, 0.))\n",
        "    accept_rate = num_accepts / (mc_steps * x.shape[0])\n",
        "    return x, accept_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqGIXyfIveSr",
        "outputId": "20d62443-0260-4ef5-bbdc-1029e4157f4e"
      },
      "outputs": [],
      "source": [
        "@partial(jax.vmap, in_axes=(0, None, None, None))\n",
        "def logp(x, n, dim, beta):\n",
        "    return -beta * energy_fn(x, n, dim)\n",
        "\n",
        "beta = 10.0 # inverse temperature\n",
        "batchsize = 8192\n",
        "mc_steps = 100 \n",
        "mc_width = 0.02\n",
        "\n",
        "x = jax.random.normal(key, (batchsize, n, dim))\n",
        "energy_fn_vmap = jax.vmap(energy_fn, (0, None, None), 0)\n",
        "\n",
        "for i in range(20):\n",
        "    key, subkey = jax.random.split(key)\n",
        "    x, acc = mcmc(lambda x: logp(x, n, dim, beta), x, subkey, mc_steps, mc_width)\n",
        "    energy = jnp.mean(energy_fn_vmap(x, n, dim))\n",
        "    print(\"%.2d    %.6f    %.6f    %.6f\" %(i, acc, mc_width, energy))\n",
        "    \n",
        "    if acc > 0.525: mc_width *= 1.05\n",
        "    if acc < 0.475: mc_width *= 0.95"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "6pdZ_L8NwDh0",
        "outputId": "4e80008e-9b90-4bea-b5d8-0911ba6d43ea"
      },
      "outputs": [],
      "source": [
        "x = jnp.reshape(x, (batchsize*n, dim)) \n",
        "#density plot\n",
        "H, xedges, yedges = np.histogram2d(x[:, 0], x[:, 1], \n",
        "                                   bins=100, \n",
        "                                   range=((-4, 4), (-4, 4)),\n",
        "                        density=True)\n",
        "\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "plt.imshow(H, interpolation=\"nearest\", \n",
        "               extent=(xedges[0], xedges[-1], yedges[0], yedges[-1]),\n",
        "               cmap=\"inferno\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create a network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_network(layer_sizes):\n",
        "    \n",
        "    def init(key, scale=1e-2):\n",
        "        params = []\n",
        "        for n_in, n_out in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
        "            weight_key, bias_key = jax.random.split(key)\n",
        "            weight = scale * jax.random.normal(weight_key, (n_in, n_out))\n",
        "            bias = scale * jax.random.normal(bias_key, (n_out,))\n",
        "            params.append((weight, bias))\n",
        "        return params\n",
        "\n",
        "    def relu(x):\n",
        "        return jnp.maximum(0, x)\n",
        "\n",
        "    def apply(params, x):\n",
        "        for w, b in params[:-1]:\n",
        "            x = relu(jnp.dot(x, w) + b)\n",
        "        final_w, final_b = params[-1]\n",
        "        return jnp.dot(x, final_w) + final_b\n",
        "\n",
        "    return init, apply\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "layer_sizes = [784, 128, 64, 10] # IN: 784 pixels, OUT: 10 classes\n",
        "init_fn, apply_fn = make_network(layer_sizes)\n",
        "key = jax.random.PRNGKey(42)\n",
        "params = init_fn(key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from jax.flatten_util import ravel_pytree\n",
        "ravel_pytree(params)[0].size # 784*128 + 128*64 + 64*10 + 128 + 64 + 10 "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPSNJ0IvKn56h3oiGUHMRnv",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
